# Join und group

## Vorbereitung

Für diese Lektion brauchen wir folgende Pakete:

```{r message=F, warning=F}
library(tidyverse)
library(sf)
library(tmap)
```

## Aufgabe

Ziel soll sein, eine Deutschlandkarte mit Tankstellenpreisen für Diesel zu erstellen.

## Daten einlesen

Das "Tankerkönig"-Projekt veröffentlicht aktuelle Tankstellenpreise über eine API, und stellt historische Preise hier bereit: https://dev.azure.com/tankerkoenig/_git/tankerkoenig-data

Wir laden die Dateien für `prices` und `stations` von einem Tag (hier: 26.5.2019) herunter und speichern sie im Unterordner `resources` des Projektordners.

Dann können wir sie einlesen:

```{r eval=F}
preise <- read_csv("resources/2019-05-26-prices.csv")
preise
```

```{r message = F, echo = F}
"https://dev.azure.com/tankerkoenig/362e70d1-bafa-4cf7-a346-1f3613304973/_apis/git/repositories/0d6e7286-91e4-402c-af56-fa75be1f223d/items?path=%2Fprices%2F2019%2F05%2F2019-05-26-prices.csv" %>%
  read_csv() -> preise
"https://dev.azure.com/tankerkoenig/362e70d1-bafa-4cf7-a346-1f3613304973/_apis/git/repositories/0d6e7286-91e4-402c-af56-fa75be1f223d/items?path=%2Fstations%2F2019%2F05%2F2019-05-26-stations.csv" %>%
  read_csv() -> tankstellen

preise
```
 
## Überblick verschaffen

Beim nähreren Betrachten fällt auf, dass im Datensatz `preise` 231.174 Zeilen enthalten sind, in `stations` nur 15.668. Das liegt daran, das für jede Station *mehrere* Preisupdates im Datensatz `preise` stehen, jedoch nur *einmal* die gleichbleibenden Informationen (Name, Marke, Adresse, Koordinaten) in `stations`.

Beide Datensätze sind über einen eindeutigen „Key“ verbunden: In `preise` heißt er `station_uuid`, in `stations` einfach nur `uuid`. 

Um ein besseres Gefühl für den Datensatz zu bekommen, könnten wir uns z.&nbsp;B. anschauen, zu welcher Uhrzeit wie viele Preise aktualisiert wurden:

```{r, message=FALSE}
ggplot(preise) +
  geom_histogram(aes(x = date))
```

## Zusammenfassen

Eine weitere Frage könnte sein: Wie sieht die Verteilung der Anzahl der Preisupdates je Tankstelle aus? Hierfür müssen wir den Datensatz `preise` anhand der Spalte `station_uuid` zusammenfassen und die Einträge zählen. Das geht mit `group_by()` und `summarize()`:

```{r, message=FALSE}
preise %>%
  group_by(station_uuid) %>%
  summarize(anzahl_updates = n()) %>%
  ggplot() +
    geom_histogram(aes(x = anzahl_updates))
```

Um unserem Ziel der Dieselkarte etwas näher zu kommen, sollten wir aber nicht die Anzahl der Updates zusammenfassen, sondern den Dieselpreis.
Aber nach welchem Schema?
Einfach nur den Durchschnitt (mit `mean()`) zu nehmen, könnte das Bild verfälschen: Man stelle sich z.&nbsp;B. vor, ein besonders teurer (oder günstiger) Preis sei nur wenige Sekunden gültig gewesen.

Wir orientieren uns einfach an der Börse und nehmen einfach den letzten gültigen Preis (wie der Aktienwert bei Börsenschluss).
Dafür müssen wir den Datensatz erst mit `arrange()` chronologisch sortieren, dann entsprechend gruppieren und mit `last()` zusammenfassen:

```{r}
preise %>%
  arrange(date) %>%
  group_by(station_uuid) %>%
  summarize(dieselpreis = last(diesel),
            e5preis     = last(e5),
            e10preis    = last(e10)) ->
  preise_nach_tankstelle

preise_nach_tankstelle
```

## Verschneiden

Jetzt haben wir für jede Station nur noch eine Zeile mit den Preisen.
Um das zu kartieren, fehlen noch die Informationen zu den Tankstellen. Dafür laden wir auch den `stations`-Datensatz für den richtigen Tag herunter und importieren ihn in R:

```{r eval = F}
tankstellen <- read_csv("resources/2019-05-26-stations.csv")
tankstellen
```

```{r echo = F}
tankstellen
```

Wir verschneiden mit `inner_join()` unter Angabe der relevanten Spaltennamen und wählen die Spalten aus, mit denen wir weiterarbeiten wollen:

```{r}
inner_join(preise_nach_tankstelle, tankstellen,
           by = c("station_uuid" = "uuid")) %>%
  select(dieselpreis, e5preis, e10preis, name, brand, latitude, longitude) ->
  preise_geo

preise_geo
```

`inner_join` hat die Besonderheit, dass nur Zeilen im kombinierten Datensatz übrigbleiben, deren Key in *beiden* Datensätzen gefunden wurde. Mit `left_join` würden hier alle Preise behalten werden (und die fehlenden Koordinaten mit `NA` ergänzt), mit `right_join` würden alle Stationen behalten werden (und fehlende Preise mit `NA` ergänzt). `full_join` löscht gar keine Informationen.

## Kartieren

Den georeferenzierten Datensatz der Preise wandeln wir in eine Simple Feature Collection um:

```{r}
preise_geo %>%
  st_as_sf(coords = c("longitude", "latitude")) -> preise_sf
```

`ggplot()` kartiert so einen großen Datensatz nur langsam. Wir nehmen stattdessen das Paket `tmap()` zur Hand, das mit einer ähnlichen Grammatik funktioniert.

Interaktive Karten lassen sich mit `tmap` produzieren, wenn die Option

```{r eval = FALSE}
tmap_mode("view")
```

gesetzt ist. Aus technischen Gründen wird an dieser Stelle im Skript darauf verzichtet und wir bleiben beim `plot`-Modus:

```{r}
tm_shape(preise_sf) +
  tm_dots()
```

Zwei Koordinaten sind quatsch! Wir finden ihre ungefähren Werte mit `summary`:

```{r}
summary(preise_geo$longitude)
```

Und filtern sie raus, und wiederholen die Umwandlung (diesmal auch mit CRS)

```{r}
preise_geo %>%
  filter(longitude < 80) %>%
  st_as_sf(coords = c("longitude", "latitude")) %>%
  st_set_crs(4326) -> preise_sf
```

Dann mappen wir nochmal:

```{r}
tm_shape(preise_sf) +
  tm_dots("dieselpreis", style = "cont")
```

Schon ganz hübsch, aber die Skala wird nun verzerrt durch sehr teure Autobahntankstellen einerseits, und falsche Null-werte andererseits:

```{r}
summary(preise_sf$dieselpreis)
```

## Choroplethen

Eine Lösung wäre, die Daten auf Kreisebene zusammenzufassen, und zwar anhand ihres Medians. Damit würden diese Ausreißer keine Role mehr spielen.

Das `eurostat`-Paket macht es einfach, diese Geodaten einzulesen. NUTS3 ist die Ebene der Stadt- und Landkreise bzw. ihrer europäischen Equivalente.

```{r, warning=F, message=F, error=F}
kreise <- eurostat::get_eurostat_geospatial(nuts_level = 3) %>%
  filter(CNTR_CODE == "DE")
```

Mal schauen wie es aussieht:

```{r}
tm_shape(kreise) +
  tm_polygons()
```

## Räumliches Verschneiden

mit `st_join` werden Datensätze nicht mit einem Key verschnitten, sondern anhand ihrer Geolokation. Dann können wir wieder ganz normal `group_by` und `summarise` verwenden:

```{r}
st_join(kreise, preise_sf) %>%
  group_by(NUTS_ID) %>%
  summarise(dieselpreis = median(dieselpreis),
            e5preis     = median(e5preis),
            e10preis    = median(e10preis)) -> preise_kreise
```

Und so könnte vielleicht ein vorläufiges Ergebnis aussehen:

```{r}
tm_shape(preise_kreise) +
  tm_fill("dieselpreis",
          title = "Median der Dieselpreise",
          style = "cont",
          alpha = 0.8) +
  tm_layout(legend.outside = TRUE)
```

